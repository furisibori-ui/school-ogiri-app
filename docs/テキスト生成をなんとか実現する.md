# テキスト生成をなんとか実現する

学校のテキスト（校名・校長・校歌歌詞など）が **Comet のチャット API** で生成されています。503「チャネルが利用できません」が出る場合は、**あなたの Comet 契約でそのモデルが使えない**か、**モデルIDの表記が違う**可能性があります。

---

## やること（優先順）

### 1. Comet のモデルカタログで「使える」モデルを確認する

1. **https://www.cometapi.com/ja/models/** を開く。
2. **チャット／LLM** の一覧から、**利用可能**（または価格が表示されている）モデルを探す。
3. そのモデルの **API 用モデルID** をコピーする。  
   - 例: `google/gemini-2.5-flash`、`openai/gpt-4o-mini`、`anthropic/claude-3-5-haiku` など。  
   - 表記はカタログや API ドキュメントの **そのまま** を使う（スペースやハイフンの違いで 503 になることがある）。

### 2. Vercel の環境変数に 1 本だけ設定する（おすすめ）

1. Vercel ダッシュボード → 対象プロジェクト → **Settings** → **環境変数**。
2. **環境変数を追加する** で、  
   - **Key**: `COMET_CHAT_MODEL`  
   - **Value**: 手順1でコピーした **モデルID をそのまま** 貼り付ける。  
3. **環境**: 本番（Production）を選び保存。
4. **再デプロイ** する（環境変数を変えただけでは反映されないため、Redeploy または push で新しいデプロイを走らせる）。

→ これで「その 1 本」でテキスト生成が通るか試せます。

### 3. それでも 503 のとき：COMET_CHAT_MODEL を削除して「自動で複数モデル試行」に任せる

1. Vercel の環境変数で **`COMET_CHAT_MODEL` を削除**（または未設定のまま）にする。
2. 再デプロイする。

コード側で、次の順に **最大 6 つまで** 自動で試します。

- 未設定時:  
  `anthropic/claude-3-5-haiku` → `anthropic/claude-3-5-sonnet` →  
  `google/gemini-2.5-flash` → `google/gemini-2.0-flash` → `openai/gpt-4o-mini`
- **設定している場合**: その 1 本を最初に試し、失敗したら上記のうち重複しないものを順に試行。

契約で **どれか 1 つでも使えていれば**、テキスト生成が通る可能性があります。

### 4. Comet のダッシュボード・請求を確認する

- **https://www.cometapi.com/console/token** で API キーと利用状況を確認。
- 請求やクレジットが切れていないか、**チャット／LLM** が契約に含まれているか確認。
- 利用可能モデルの一覧がダッシュボードにあれば、そこに書いてある **モデルID** を `COMET_CHAT_MODEL` に設定する。

---

## コード側でやっていること

- **`COMET_CHAT_MODEL` が設定されている場合**  
  そのモデルを最初に 1 回試し、503 などで失敗したら、  
  Claude（Haiku/Sonnet）→ Gemini → GPT-4o-mini の順で、**重複しないように最大 6 モデル** まで試行します。
- **`COMET_CHAT_MODEL` が未設定の場合**  
  上記の複数モデルを先頭から順に試行します。

「なんとか 1 本でも通したい」というときは、**まずカタログで確実に利用可能なモデルIDを 1 本だけ `COMET_CHAT_MODEL` に設定**し、それでもダメなら **COMET_CHAT_MODEL を削除して自動試行** に任せるのがおすすめです。

---

## API キーは 1 本だけ

**6 モデル試行しても、使う API キーは COMET_API_KEY の 1 本だけ**です。6 個の「モデルID」を順に試しているだけで、キーを 6 つ登録する必要はありません。Comet が複数プロバイダ（Claude / Gemini / GPT など）を 1 つのキーでまとめて提供しているためです。

---

## 成功したモデルを記録して次回に活かす

**一度どれか 1 本で通ると、そのモデルIDを Vercel KV に 7 日間キャッシュ**します。次回以降はそのモデルを **最初に 1 本だけ試し**、通ればそこで終わりなので、**無駄な API 呼び出しが減ります**。失敗したときだけ、ほかのモデルを順に試します。

---

## モック表示時の画像・校歌の使い回し

テキストがモック（フォールバック）で返った場合でも、これまで Step2 で画像 API・Step3 で校歌 API を毎回呼んでいました。**モックのときは、一度生成した画像・校歌の URL を KV に 30 日間キャッシュし、次回以降のモック表示ではそれを使い回す**ようにしています。API を無駄にせず、表示も安定します。
